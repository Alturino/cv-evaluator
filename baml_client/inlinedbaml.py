# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\nclient<llm> CustomGemini {\n  provider google-ai\n  options {\n    model \"gemini-2.5-flash\" // gemini-2.5-pro\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.208.5\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "resume.baml": "// Defining a data model.\nclass Education {\n  school string\n  gpa float\n  max_gpa float\n}\n\nclass Experience {\n  company string\n  position string\n  location string\n  start_date string\n  end_date string\n  description string\n  responsibilities string[]\n}\n\nclass Resume {\n  name string\n  address string\n  projects string[]\n  educations Education[]\n  experience Experience[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  client \"google-ai/gemini-2.5-flash\"\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest ricky_alturino_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Ricky Alturino\n      Software Engineer\n      Palembang, Indonesia | +6285156906761 | rickyalturino001@gmail.com | LinkedIn | Github\n      EXPERIENCE\n      Brick\n      (Remote) Jakarta, Indonesia\n      L1 Engineer\n      May 2024 – May 2025\n      Provide cross-divisional support both in data updates and data retrieval.\n       Developed, maintained applications/services.\n      Campaign\n      (Remote) Jakarta, Indonesia\n      Android Developer Intern\n      January 2023 – July 2023\n       Collaborated with teams to ensure features are meeting expectations.\n       Developed, maintained, and tested new features.\n      Indosat Ooredoo Hutchison\n      (Remote) Jakarta, Indonesia\n      Android Developer Intern\n      May 2022 – June 2022\n      ●Lead Mobile Development Team to develop Hy.Ponics application.\n      ●Researched, developed, and tested features of Hy.Ponics application.\n      SKILLS\n      Programming: Go, Java, Kotlin, TypeScript, Python, OOP, Design Pattern, TDD.\n      Framework: Gin, Fiber, Echo, Spring Boot, Express, Hapi, NestJS, React.\n      CI/CD: Github Actions, Circle CI.\n      Database: PostgreSQL, MySQL, MongoDB, Redis, Memcached, Firebase.\n      Message Queue/PubSub: RabbitMQ, Kafka, NATS, Firebase Cloud Messaging.\n      Others: Git, Linux, Docker, Kubernetes, k6, Testcontainers, Prometheus, Grafana, Nginx, AWS, GCP.\n      AWARDS\n      Best Team Company Capstone, Bangkit Academy, July 2022.\n      Best Team Member Company Capstone, Bangkit Academy, July 2022.\n      EDUCATION\n      Sriwijaya University\n      Palembang, Indonesia\n      Bachelor of Computer Science (GPA 3.60/4.00)\n      2019 – 2023\n      Coursework: Algorithm & Data Structures, Software Engineering, Database, Operating Systems\n      GoTo Impact Foundation (Generasi Gigih 3.0)\n      Fullstack Engineering Track(Remote) Jakarta, Indonesia\n      June 2023 – December 2023\n      Hacktiv8\n      Backend Engineering Go(Remote) Jakarta, Indonesia\n      March 2023 – April 2023\n      PROJECTS\n      Hedonify\n      April 2024 - February 2025\n      Scalable ecommerce microservices-based backend system, implemented a queue and batch processing to\n      handle competing orders efficiently.\n      Tech stack: Go, Docker, Microservice, PostgreSQL, Redis, OpenTelemetry.\n      Open Music API\n      April 2024 - September 2024\n      Music backend server for dicoding course.\n      Tech stack: JavaScript (Hapi), Java (Spring Boot), PostgreSQL, RabbitMQ.\n      Learn Kubernetes\n      April 2024 - April 2024\n      Learn kubernetes deployment and database replication of MongoDB, PostgreSQL, and Redis by using\n      Docker Compose and Kubernetes StatefulSet.\n      Tech stack: MongoDB, PostgreSQL, Redis, Docker, Kubernetes.\n      CERTIFICATIONS\n      ●Google Developer: Associate Android Developer\n      ●Dicoding: Android Expert | Backend Fundamental | React Fundamental | Machine Learning\n      ●Hackerrank: SQL (Advanced) | Software Engineer | Problem Solving (Intermediate) | Go\n      (Intermediate) | Javascript (Intermediate)\n      ●Others: Android Performance.\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return _file_map