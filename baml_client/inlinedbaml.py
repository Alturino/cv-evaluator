# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\nclient<llm> CustomGemini {\n  provider google-ai\n  options {\n    model \"gemini-2.5-flash\" // gemini-2.5-pro\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.208.5\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "job_description.baml": "// Defining a data model.\nclass JobDescription {\n  description string\n  qualifications string[]\n  tools string[]\n  real_work_examples string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractJobDescription(job: string) -> JobDescription {\n  client CustomGemini\n  prompt #\"\n    Extract from this content:\n    {{ job }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest rakamin_job_description {\n  functions [ExtractJobDescription]\n  args {\n    job #\"\n            Tool\n\n            Node.js\n            Ruby on Rails\n            LLM\n            Docker\n            Kubernetes\n            Description\n\n            You'll be building new product features alongside a frontend engineer and product manager using our Agile methodology, as well as addressing issues to ensure our apps are robust and our codebase is clean. As a Product Engineer, you'll write clean, efficient code to enhance our product's codebase in meaningful ways.\n\n            In addition to classic backend work, this role also touches on building AI-powered systems, where you’ll design and orchestrate how large language models (LLMs) integrate into Rakamin’s product ecosystem.\n\n            Here are some real examples of the work in our team:\n\n            Collaborating with frontend engineers and 3rd parties to build robust backend solutions that support highly configurable platforms and cross-platform integration.\n            Developing and maintaining server-side logic for central database, ensuring high performance throughput and response time.\n            Designing and fine-tuning AI prompts that align with product requirements and user contexts.\n            Building LLM chaining flows, where the output from one model is reliably passed to and enriched by another.\n            Implementing Retrieval-Augmented Generation (RAG) by embedding and retrieving context from vector databases, then injecting it into AI prompts to improve accuracy and relevance.\n            Handling long-running AI processes gracefully — including job orchestration, async background workers, and retry mechanisms.\n            Designing safeguards for uncontrolled scenarios: managing failure cases from 3rd party APIs and mitigating the randomness/nondeterminism of LLM outputs.\n            Leveraging AI tools and workflows to increase team productivity (e.g., AI-assisted code generation, automated QA, internal bots).\n            Writing reusable, testable, and efficient code to improve the functionality of our existing systems.\n            Strengthening our test coverage with RSpec to build robust and reliable web apps.\n            Conducting full product lifecycles, from idea generation to design, implementation, testing, deployment, and maintenance.\n            Providing input on technical feasibility, timelines, and potential product trade-offs, working with business divisions.\n            Actively engaging with users and stakeholders to understand their needs and translate them into backend and AI-driven improvements.\n\n            Required qualification\n\n            We’re looking for candidates with a strong track record of working on backend technologies of web apps, ideally with exposure to AI/LLM development or a strong desire to learn.\n\n            You should have experience with backend languages and frameworks (Node.js, Django, Rails), as well as modern backend tooling and technologies such as:\n\n            Database management (MySQL, PostgreSQL, MongoDB)\n            RESTful APIs\n            Security compliance\n            Cloud technologies (AWS, Google Cloud, Azure)\n            Server-side languages (Java, Python, Ruby, or JavaScript)\n            Understanding of frontend technologies\n            User authentication and authorization between multiple systems, servers, and environments\n            Scalable application design principles\n            Creating database schemas that represent and support business processes\n            Implementing automated testing platforms and unit tests\n            Familiarity with LLM APIs, embeddings, vector databases and prompt design best practices\n            We're not big on credentials, so a Computer Science degree or graduating from a prestigious university isn't something we emphasize. We care about what you can do and how you do it, not how you got here.\n\n            While you'll report to a CTO directly, Rakamin is a company where Managers of One thrive. We're quick to trust that you can do it, and here to support you. You can expect to be counted on and do your best work and build a career here.\n\n            This is a remote job. You're free to work where you work best: home office, co-working space, coffee shops. To ensure time zone overlap with our current team and maintain well communication, we're only looking for people based in Indonesia.\n    \"#\n  }\n}\n\n",
    "resume.baml": "// Defining a data model.\nclass Education {\n  school string\n  gpa float\n  max_gpa float\n}\n\nclass Experience {\n  company string\n  position string\n  location string\n  start_date string\n  end_date string\n  duration_in_year float\n  description string\n  responsibilities string[]\n}\n\nclass Project{\n  name string\n  description string\n  technologies string[]\n  tools string[]\n  duration_in_year float\n}\n\nclass Resume {\n  name string\n  address string\n  projects Project[]\n  educations Education[]\n  experience Experience[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  client CustomGemini\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest ricky_alturino_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Ricky Alturino\n      Software Engineer\n      Palembang, Indonesia | +6285156906761 | rickyalturino001@gmail.com | LinkedIn | Github\n      EXPERIENCE\n      Brick\n      (Remote) Jakarta, Indonesia\n      L1 Engineer\n      May 2024 – May 2025\n      Provide cross-divisional support both in data updates and data retrieval.\n       Developed, maintained applications/services.\n      Campaign\n      (Remote) Jakarta, Indonesia\n      Android Developer Intern\n      January 2023 – July 2023\n       Collaborated with teams to ensure features are meeting expectations.\n       Developed, maintained, and tested new features.\n      Indosat Ooredoo Hutchison\n      (Remote) Jakarta, Indonesia\n      Android Developer Intern\n      May 2022 – June 2022\n      ●Lead Mobile Development Team to develop Hy.Ponics application.\n      ●Researched, developed, and tested features of Hy.Ponics application.\n      SKILLS\n      Programming: Go, Java, Kotlin, TypeScript, Python, OOP, Design Pattern, TDD.\n      Framework: Gin, Fiber, Echo, Spring Boot, Express, Hapi, NestJS, React.\n      CI/CD: Github Actions, Circle CI.\n      Database: PostgreSQL, MySQL, MongoDB, Redis, Memcached, Firebase.\n      Message Queue/PubSub: RabbitMQ, Kafka, NATS, Firebase Cloud Messaging.\n      Others: Git, Linux, Docker, Kubernetes, k6, Testcontainers, Prometheus, Grafana, Nginx, AWS, GCP.\n      AWARDS\n      Best Team Company Capstone, Bangkit Academy, July 2022.\n      Best Team Member Company Capstone, Bangkit Academy, July 2022.\n      EDUCATION\n      Sriwijaya University\n      Palembang, Indonesia\n      Bachelor of Computer Science (GPA 3.60/4.00)\n      2019 – 2023\n      Coursework: Algorithm & Data Structures, Software Engineering, Database, Operating Systems\n      GoTo Impact Foundation (Generasi Gigih 3.0)\n      Fullstack Engineering Track(Remote) Jakarta, Indonesia\n      June 2023 – December 2023\n      Hacktiv8\n      Backend Engineering Go(Remote) Jakarta, Indonesia\n      March 2023 – April 2023\n      PROJECTS\n      Hedonify\n      April 2024 - February 2025\n      Scalable ecommerce microservices-based backend system, implemented a queue and batch processing to\n      handle competing orders efficiently.\n      Tech stack: Go, Docker, Microservice, PostgreSQL, Redis, OpenTelemetry.\n      Open Music API\n      April 2024 - September 2024\n      Music backend server for dicoding course.\n      Tech stack: JavaScript (Hapi), Java (Spring Boot), PostgreSQL, RabbitMQ.\n      Learn Kubernetes\n      April 2024 - April 2024\n      Learn kubernetes deployment and database replication of MongoDB, PostgreSQL, and Redis by using\n      Docker Compose and Kubernetes StatefulSet.\n      Tech stack: MongoDB, PostgreSQL, Redis, Docker, Kubernetes.\n      CERTIFICATIONS\n      ●Google Developer: Associate Android Developer\n      ●Dicoding: Android Expert | Backend Fundamental | React Fundamental | Machine Learning\n      ●Hackerrank: SQL (Advanced) | Software Engineer | Problem Solving (Intermediate) | Go\n      (Intermediate) | Javascript (Intermediate)\n      ●Others: Android Performance.\n    \"#\n  }\n}\n",
    "resume_evaluator.baml": "class SkillResult {\n    score int\n    feedback string\n}\n\nclass EvaluationResult {\n    cv_match_rate float\n    cv_feedback string\n    project_score float\n    project_feedback string\n    overall_summary string\n    technical_skills_match SkillResult\n    experience_level SkillResult\n    project_match SkillResult\n    relevant_achievements SkillResult\n    cultural_fit SkillResult\n}\n\nfunction EvaluateResume(resume: Resume, job_description: JobDescription) -> EvaluationResult {\n    client CustomGemini\n    prompt #\"\n        **Instructions:**\n        You are an expert HR and Technical Recruiter. Your task is to evaluate a candidate's CV against a job description, providing a score and feedback for each of the following criteria.\n\n        **Job Description:**\n        {{job_description}}\n\n        **Candidate's CV:**\n        {{resume}}\n\n        **Evaluation Criteria:**\n\n        1.  **Technical Skills Match (1-5):**\n            * **Description:** How well do the candidate's backend, databases, APIs, cloud, and AI/LLM skills align with the job description?\n            * **Score:** (1-5, where 1 is \"Irrelevant skills\" and 5 is \"Excellent match + AI/LLM exposure\")\n            * **Feedback:** [Provide a brief justification for the score, highlighting key strengths or gaps in skills.]\n\n        2.  **Experience Level (1-5):**\n            * **Description:** Assess the candidate's years of experience and the complexity of their past projects.\n            * **Score:** (1-5, where 1 is \"<1 yr / trivial projects\" and 5 is \"5+ yrs / high-impact projects\")\n            * **Feedback:** [Provide a brief justification for the score, mentioning project scope or years of experience.]\n\n        3.  **Relevant Achievements (1-5):**\n            * **Description:** Evaluate the impact and scale of the candidate's past work. Look for measurable outcomes.\n            * **Score:** (1-5, where 1 is \"No clear achievements\" and 5 is \"Major measurable impact\")\n            * **Feedback:** [Provide a brief justification for the score, citing specific achievements or noting their absence.]\n\n        4.  **Cultural Fit (1-5):**\n            * **Description:** Based on the CV's tone and content, assess the candidate's communication skills and learning attitude.\n            * **Score:** (1-5, where 1 is \"Not demonstrated\" and 5 is \"Excellent and well-demonstrated\")\n            * **Feedback:** [Provide a brief justification for the score, commenting on clarity, detail, or demonstrated a growth mindset.]\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n\ntest rakamin_job_description {\n  functions [EvaluateResume]\n  args {\n        resume {\n            name: \"Ricky Alturino\",\n            address: \"Palembang, Indonesia\",\n            projects: [\n                {\n                name: \"Hedonify\",\n                description: \"Scalable ecommerce microservices-based backend system, implemented a queue and batch processing to handle competing orders efficiently.\",\n                technologies: [\n                    \"Go\",\n                    \"Docker\",\n                    \"Microservice\",\n                    \"PostgreSQL\",\n                    \"Redis\",\n                    \"OpenTelemetry\"\n                ],\n                tools: [],\n                duration_in_year: 0.92\n                },\n                {\n                name: \"Open Music API\",\n                description: \"Music backend server for dicoding course.\",\n                technologies: [\n                    \"JavaScript (Hapi)\",\n                    \"Java (Spring Boot)\",\n                    \"PostgreSQL\",\n                    \"RabbitMQ\"\n                ],\n                tools: [],\n                duration_in_year: 0.5\n                },\n                {\n                name: \"Learn Kubernetes\",\n                description: \"Learn kubernetes deployment and database replication of MongoDB, PostgreSQL, and Redis by using Docker Compose and Kubernetes StatefulSet.\",\n                technologies: [\n                    \"MongoDB\",\n                    \"PostgreSQL\",\n                    \"Redis\",\n                    \"Docker\",\n                    \"Kubernetes\"\n                ],\n                tools: [],\n                duration_in_year: 0.08\n                }\n            ],\n            educations: [\n                {\n                school: \"Sriwijaya University\",\n                gpa: 3.6,\n                max_gpa: 4\n                }\n            ],\n            experience: [\n                {\n                company: \"Brick\",\n                position: \"L1 Engineer\",\n                location: \"(Remote) Jakarta, Indonesia\",\n                start_date: \"May 2024\",\n                end_date: \"May 2025\",\n                duration_in_year: 1.08,\n                description: \"\",\n                responsibilities: [\n                    \"Provide cross-divisional support both in data updates and data retrieval.\",\n                    \"Developed, maintained applications/services.\"\n                ]\n                },\n                {\n                company: \"Campaign\",\n                position: \"Android Developer Intern\",\n                location: \"(Remote) Jakarta, Indonesia\",\n                start_date: \"January 2023\",\n                end_date: \"July 2023\",\n                duration_in_year: 0.58,\n                description: \"\",\n                responsibilities: [\n                    \"Collaborated with teams to ensure features are meeting expectations.\",\n                    \"Developed, maintained, and tested new features.\"\n                ]\n                },\n                {\n                company: \"Indosat Ooredoo Hutchison\",\n                position: \"Android Developer Intern\",\n                location: \"(Remote) Jakarta, Indonesia\",\n                start_date: \"May 2022\",\n                end_date: \"June 2022\",\n                duration_in_year: 0.17,\n                description: \"\",\n                responsibilities: [\n                    \"Lead Mobile Development Team to develop Hy.Ponics application.\",\n                    \"Researched, developed, and tested features of Hy.Ponics application.\"\n                ]\n                }\n            ],\n            skills: [\n                \"Go\",\n                \"Java\",\n                \"Kotlin\",\n                \"TypeScript\",\n                \"Python\",\n                \"OOP\",\n                \"Design Pattern\",\n                \"TDD\",\n                \"Gin\",\n                \"Fiber\",\n                \"Echo\",\n                \"Spring Boot\",\n                \"Express\",\n                \"Hapi\",\n                \"NestJS\",\n                \"React\",\n                \"Github Actions\",\n                \"Circle CI\",\n                \"PostgreSQL\",\n                \"MySQL\",\n                \"MongoDB\",\n                \"Redis\",\n                \"Memcached\",\n                \"Firebase\",\n                \"RabbitMQ\",\n                \"Kafka\",\n                \"NATS\",\n                \"Firebase Cloud Messaging\",\n                \"Git\",\n                \"Linux\",\n                \"Docker\",\n                \"Kubernetes\",\n                \"k6\",\n                \"Testcontainers\",\n                \"Prometheus\",\n                \"Grafana\",\n                \"Nginx\",\n                \"AWS\",\n                \"GCP\"\n            ]\n} \n    job_description {\n        description: \"You'll be building new product features alongside a frontend engineer and product manager using our Agile methodology, as well as addressing issues to ensure our apps are robust and our codebase is clean. As a Product Engineer, you'll write clean, efficient code to enhance our product's codebase in meaningful ways. In addition to classic backend work, this role also touches on building AI-powered systems, where you’ll design and orchestrate how large language models (LLMs) integrate into Rakamin’s product ecosystem.\",\n        qualifications: [\n            \"Strong track record of working on backend technologies of web apps\",\n            \"Exposure to AI/LLM development or a strong desire to learn\",\n            \"Experience with backend languages and frameworks (Node.js, Django, Rails)\",\n            \"Experience with Database management (MySQL, PostgreSQL, MongoDB)\",\n            \"Experience with RESTful APIs\",\n            \"Experience with Security compliance\",\n            \"Experience with Cloud technologies (AWS, Google Cloud, Azure)\",\n            \"Experience with Server-side languages (Java, Python, Ruby, or JavaScript)\",\n            \"Understanding of frontend technologies\",\n            \"Experience with User authentication and authorization between multiple systems, servers, and environments\",\n            \"Knowledge of Scalable application design principles\",\n            \"Experience creating database schemas that represent and support business processes\",\n            \"Experience implementing automated testing platforms and unit tests\",\n            \"Familiarity with LLM APIs, embeddings, vector databases and prompt design best practices\",\n            \"Ability to demonstrate practical skills and how work is done, rather than solely relying on academic credentials (e.g., Computer Science degree or prestigious university)\"\n        ],\n        tools: [\n            \"Node.js\",\n            \"Ruby on Rails\",\n            \"LLM\",\n            \"Docker\",\n            \"Kubernetes\",\n            \"Django\",\n            \"MySQL\",\n            \"PostgreSQL\",\n            \"MongoDB\",\n            \"AWS\",\n            \"Google Cloud\",\n            \"Azure\",\n            \"Java\",\n            \"Python\",\n            \"Ruby\",\n            \"JavaScript\",\n            \"RSpec\",\n            \"Vector databases\"\n        ],\n        real_work_examples: [\n            \"Collaborating with frontend engineers and 3rd parties to build robust backend solutions that support highly configurable platforms and cross-platform integration.\",\n            \"Developing and maintaining server-side logic for central database, ensuring high performance throughput and response time.\",\n            \"Designing and fine-tuning AI prompts that align with product requirements and user contexts.\",\n            \"Building LLM chaining flows, where the output from one model is reliably passed to and enriched by another.\",\n            \"Implementing Retrieval-Augmented Generation (RAG) by embedding and retrieving context from vector databases, then injecting it into AI prompts to improve accuracy and relevance.\",\n            \"Handling long-running AI processes gracefully — including job orchestration, async background workers, and retry mechanisms.\",\n            \"Designing safeguards for uncontrolled scenarios: managing failure cases from 3rd party APIs and mitigating the randomness/nondeterminism of LLM outputs.\",\n            \"Leveraging AI tools and workflows to increase team productivity (e.g., AI-assisted code generation, automated QA, internal bots).\",\n            \"Writing reusable, testable, and efficient code to improve the functionality of our existing systems.\",\n            \"Strengthening our test coverage with RSpec to build robust and reliable web apps.\",\n            \"Conducting full product lifecycles, from idea generation to design, implementation, testing, deployment, and maintenance.\",\n            \"Providing input on technical feasibility, timelines, and potential product trade-offs, working with business divisions.\",\n            \"Actively engaging with users and stakeholders to understand their needs and translate them into backend and AI-driven improvements.\"\n        ]\n    } \n  }\n}",
}

def get_baml_files():
    return _file_map