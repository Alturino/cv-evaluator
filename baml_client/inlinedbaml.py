# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\nclient<llm> CustomGemini {\n  provider google-ai\n  options {\n    model \"gemini-2.5-flash\" // gemini-2.5-pro\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.208.5\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "job_description.baml": "// Defining a data model.\nclass JobDescription {\n  description string\n  qualifications string[]\n  tools string[]\n  real_work_examples string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractJobDescription(job: string) -> JobDescription {\n  client CustomGemini\n  prompt #\"\n    Extract from this content:\n    {{ job }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest rakamin_job_description {\n  functions [ExtractJobDescription]\n  args {\n    job #\"\n            Tool\n\n            Node.js\n            Ruby on Rails\n            LLM\n            Docker\n            Kubernetes\n            Description\n\n            You'll be building new product features alongside a frontend engineer and product manager using our Agile methodology, as well as addressing issues to ensure our apps are robust and our codebase is clean. As a Product Engineer, you'll write clean, efficient code to enhance our product's codebase in meaningful ways.\n\n            In addition to classic backend work, this role also touches on building AI-powered systems, where you’ll design and orchestrate how large language models (LLMs) integrate into Rakamin’s product ecosystem.\n\n            Here are some real examples of the work in our team:\n\n            Collaborating with frontend engineers and 3rd parties to build robust backend solutions that support highly configurable platforms and cross-platform integration.\n            Developing and maintaining server-side logic for central database, ensuring high performance throughput and response time.\n            Designing and fine-tuning AI prompts that align with product requirements and user contexts.\n            Building LLM chaining flows, where the output from one model is reliably passed to and enriched by another.\n            Implementing Retrieval-Augmented Generation (RAG) by embedding and retrieving context from vector databases, then injecting it into AI prompts to improve accuracy and relevance.\n            Handling long-running AI processes gracefully — including job orchestration, async background workers, and retry mechanisms.\n            Designing safeguards for uncontrolled scenarios: managing failure cases from 3rd party APIs and mitigating the randomness/nondeterminism of LLM outputs.\n            Leveraging AI tools and workflows to increase team productivity (e.g., AI-assisted code generation, automated QA, internal bots).\n            Writing reusable, testable, and efficient code to improve the functionality of our existing systems.\n            Strengthening our test coverage with RSpec to build robust and reliable web apps.\n            Conducting full product lifecycles, from idea generation to design, implementation, testing, deployment, and maintenance.\n            Providing input on technical feasibility, timelines, and potential product trade-offs, working with business divisions.\n            Actively engaging with users and stakeholders to understand their needs and translate them into backend and AI-driven improvements.\n\n            Required qualification\n\n            We’re looking for candidates with a strong track record of working on backend technologies of web apps, ideally with exposure to AI/LLM development or a strong desire to learn.\n\n            You should have experience with backend languages and frameworks (Node.js, Django, Rails), as well as modern backend tooling and technologies such as:\n\n            Database management (MySQL, PostgreSQL, MongoDB)\n            RESTful APIs\n            Security compliance\n            Cloud technologies (AWS, Google Cloud, Azure)\n            Server-side languages (Java, Python, Ruby, or JavaScript)\n            Understanding of frontend technologies\n            User authentication and authorization between multiple systems, servers, and environments\n            Scalable application design principles\n            Creating database schemas that represent and support business processes\n            Implementing automated testing platforms and unit tests\n            Familiarity with LLM APIs, embeddings, vector databases and prompt design best practices\n            We're not big on credentials, so a Computer Science degree or graduating from a prestigious university isn't something we emphasize. We care about what you can do and how you do it, not how you got here.\n\n            While you'll report to a CTO directly, Rakamin is a company where Managers of One thrive. We're quick to trust that you can do it, and here to support you. You can expect to be counted on and do your best work and build a career here.\n\n            This is a remote job. You're free to work where you work best: home office, co-working space, coffee shops. To ensure time zone overlap with our current team and maintain well communication, we're only looking for people based in Indonesia.\n    \"#\n  }\n}\n\n",
    "project_evaluator.baml": "class ProjectEvaluationResult {\n    overall float\n    correctness float\n    code_quality float\n    resilience float\n    documentation float\n    creativity_and_bonus float\n    feedback string\n}\n\nfunction EvaluateProject(project: string) -> ProjectEvaluationResult {\n    client CustomGemini\n    prompt #\"\n        You are an expert technical reviewer evaluating a project submission.\n\n        Project Source File Content:\n        {{ project }}\n\n        Please evaluate this project based on the following criteria (1-5 scale each):\n        1. Correctness (25% weight): meets requirements, prompt design, LLM chaining, RAG, error handling\n        2. Code Quality (20% weight): clean, modular, testable, best practices\n        3. Resilience (20% weight): handles failures, retries, monitoring, graceful degradation\n        4. Documentation (15% weight): clear README, API docs, architecture decisions, trade-offs\n        5. Creativity/Bonus (20% weight): additional features, performance optimization, security, deployment\n\n        Provide an overall score out of 10 and detailed feedback.\n        {{ ctx.output_format }}\n    \"#\n}\n\n\ntest evaluate_project {\n  functions [EvaluateProject]\n  args {\n         project #\"\n            ```python\n                import base64\n                import logging\n                import os\n                import uuid\n                from pathlib import Path\n\n                from docling.datamodel.base_models import InputFormat\n                from docling.document_converter import DocumentConverter\n                from dotenv import load_dotenv\n                from fastapi import FastAPI, HTTPException, UploadFile\n                from fastapi.responses import JSONResponse\n                from sqlmodel import select\n                from starlette.status import (\n                    HTTP_400_BAD_REQUEST,\n                )\n\n                from model.db import SessionDep, migrations\n                from model.document import Document, DocumentStatus\n                from model.requests.body import EvaluateRequest\n\n                MAX_REQUEST_SIZE = 2 * 1024 * 1024\n\n\n                load_dotenv()\n                logger = logging.getLogger(\"uvicorn.access\")\n                logger.setLevel(logging.INFO)\n                migrations()\n                app = FastAPI()\n\n\n                @app.post(\"/upload\")\n                async def upload(\n                    file: UploadFile,\n                    session: SessionDep,\n                ):\n                    if not file.filename:\n                        logger.info(\"file.filename\", file.filename, \"file should have filename\")\n                        raise HTTPException(\n                            status_code=HTTP_400_BAD_REQUEST,\n                            detail=\"file should have filename\",\n                        )\n\n                    allowed_extension = (\".txt\", \".docx\", \".pdf\")\n                    if not file.filename.endswith(allowed_extension):\n                        logger.info(\"file.filename\", file.filename)\n                        raise HTTPException(\n                            status_code=HTTP_400_BAD_REQUEST,\n                            detail=\"only accept .txt, .docx, .pdf\",\n                        )\n\n                    id = uuid.uuid4()\n                    upload_dir = os.getenv(\"UPLOAD_DIR\")\n                    upload_dir = Path(upload_dir) if upload_dir else Path.cwd().joinpath(\"uploads\")\n                    upload_path = upload_dir.joinpath(f\"{str(id)}_{file.filename}\")\n                    os.makedirs(name=upload_dir, exist_ok=True)\n\n                    file_content = await file.read()\n                    b64_encoded = base64.b64encode(file_content)\n                    with upload_path.open(\"wb\") as f:\n                        f.write(file_content)\n\n                    with session as s:\n                        s.add(\n                            Document(\n                                id=id,\n                                name=file.filename,\n                                content=b64_encoded,\n                                path=str(upload_path),\n                                status=DocumentStatus.queued,\n                            )\n                        )\n                        s.commit()\n\n                    return JSONResponse({\"id\": str(id), \"status\": str(DocumentStatus.queued)})\n\n\n                @app.post(\"/evaluate\")\n                async def evaluate(req_body: EvaluateRequest, session: SessionDep) -> JSONResponse:\n                    with session as s:\n                        statement = (\n                            select(Document)\n                            .where(Document.name == req_body.cv_file)\n                            .where(Document.id == req_body.id)\n                        )\n                        cv = s.exec(statement).first()\n                        if not cv:\n                            raise HTTPException(\n                                status_code=HTTP_400_BAD_REQUEST,\n                                detail=\"cv file not found\",\n                            )\n\n                        statement = (\n                            select(Document)\n                            .where(Document.name == req_body.project_file)\n                            .where(Document.id == req_body.id)\n                        )\n                        project = s.exec(statement).first()\n                        file_paths = [cv.path, project.path] if project else [cv.path]\n\n                        doc_converter = DocumentConverter(\n                            allowed_formats=[InputFormat.PDF, InputFormat.DOCX, InputFormat.MD],\n                        )\n                        for path in file_paths:\n                            conv_res = doc_converter.convert(path)\n\n                    return JSONResponse({\"status\": \"ok\", \"message\": \"ok\"})\n            ```\n         \"# \n  }\n}\n",
    "resume.baml": "// Defining a data model.\nclass Education {\n  school string\n  gpa float\n  max_gpa float\n}\n\nclass Experience {\n  company string\n  position string\n  location string\n  start_date string\n  end_date string\n  duration_in_year float\n  description string\n  responsibilities string[]\n}\n\nclass Project{\n  name string\n  description string\n  technologies string[]\n  tools string[]\n  duration_in_year float\n}\n\nclass CVExtractionResult {\n  name string\n  address string\n  projects Project[]\n  educations Education[]\n  experience Experience[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractCV(cv: string) -> CVExtractionResult {\n  client CustomGemini\n  prompt #\"\n    Extract from this content:\n    {{ cv }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest ricky_alturino_cv {\n  functions [ExtractCV]\n  args {\n    cv #\"\n      Ricky Alturino\n      Software Engineer\n      Palembang, Indonesia | +6285156906761 | rickyalturino001@gmail.com | LinkedIn | Github\n      EXPERIENCE\n      Brick\n      (Remote) Jakarta, Indonesia\n      L1 Engineer\n      May 2024 – May 2025\n      Provide cross-divisional support both in data updates and data retrieval.\n       Developed, maintained applications/services.\n      Campaign\n      (Remote) Jakarta, Indonesia\n      Android Developer Intern\n      January 2023 – July 2023\n       Collaborated with teams to ensure features are meeting expectations.\n       Developed, maintained, and tested new features.\n      Indosat Ooredoo Hutchison\n      (Remote) Jakarta, Indonesia\n      Android Developer Intern\n      May 2022 – June 2022\n      ●Lead Mobile Development Team to develop Hy.Ponics application.\n      ●Researched, developed, and tested features of Hy.Ponics application.\n      SKILLS\n      Programming: Go, Java, Kotlin, TypeScript, Python, OOP, Design Pattern, TDD.\n      Framework: Gin, Fiber, Echo, Spring Boot, Express, Hapi, NestJS, React.\n      CI/CD: Github Actions, Circle CI.\n      Database: PostgreSQL, MySQL, MongoDB, Redis, Memcached, Firebase.\n      Message Queue/PubSub: RabbitMQ, Kafka, NATS, Firebase Cloud Messaging.\n      Others: Git, Linux, Docker, Kubernetes, k6, Testcontainers, Prometheus, Grafana, Nginx, AWS, GCP.\n      AWARDS\n      Best Team Company Capstone, Bangkit Academy, July 2022.\n      Best Team Member Company Capstone, Bangkit Academy, July 2022.\n      EDUCATION\n      Sriwijaya University\n      Palembang, Indonesia\n      Bachelor of Computer Science (GPA 3.60/4.00)\n      2019 – 2023\n      Coursework: Algorithm & Data Structures, Software Engineering, Database, Operating Systems\n      GoTo Impact Foundation (Generasi Gigih 3.0)\n      Fullstack Engineering Track(Remote) Jakarta, Indonesia\n      June 2023 – December 2023\n      Hacktiv8\n      Backend Engineering Go(Remote) Jakarta, Indonesia\n      March 2023 – April 2023\n      PROJECTS\n      Hedonify\n      April 2024 - February 2025\n      Scalable ecommerce microservices-based backend system, implemented a queue and batch processing to\n      handle competing orders efficiently.\n      Tech stack: Go, Docker, Microservice, PostgreSQL, Redis, OpenTelemetry.\n      Open Music API\n      April 2024 - September 2024\n      Music backend server for dicoding course.\n      Tech stack: JavaScript (Hapi), Java (Spring Boot), PostgreSQL, RabbitMQ.\n      Learn Kubernetes\n      April 2024 - April 2024\n      Learn kubernetes deployment and database replication of MongoDB, PostgreSQL, and Redis by using\n      Docker Compose and Kubernetes StatefulSet.\n      Tech stack: MongoDB, PostgreSQL, Redis, Docker, Kubernetes.\n      CERTIFICATIONS\n      ●Google Developer: Associate Android Developer\n      ●Dicoding: Android Expert | Backend Fundamental | React Fundamental | Machine Learning\n      ●Hackerrank: SQL (Advanced) | Software Engineer | Problem Solving (Intermediate) | Go\n      (Intermediate) | Javascript (Intermediate)\n      ●Others: Android Performance.\n    \"#\n  }\n}\n",
    "resume_evaluator.baml": "class SkillResult {\n    score int\n    feedback string\n}\n\nclass OverallResult {\n    cv_match_rate float\n    cv_feedback string\n    project_score float\n    project_feedback string\n    overall_summary string\n    technical_skills_match SkillResult\n    experience_level SkillResult\n    project_match SkillResult\n    relevant_achievements SkillResult\n    cultural_fit SkillResult\n}\n\nfunction EvaluateAll(cv: CVExtractionResult,  job_description: JobDescription, project_evaluation: ProjectEvaluationResult) -> OverallResult {\n    client CustomGemini\n    prompt #\"\n        **Instructions:**\n        You are an expert HR and Technical Recruiter. Your task is to evaluate a candidate's CV against a job description, providing a score and feedback for each of the following criteria.\n\n        **Job Description:**\n        {{job_description}}\n\n        **Candidate's CV:**\n        {{ cv }}\n        \n        **Candiate's Project Evaluation:**\n        {{project_evaluation}}\n\n        **Evaluation Criteria:**\n\n        1.  **Technical Skills Match (1-5):**\n            * **Description:** How well do the candidate's backend, databases, APIs, cloud, and AI/LLM skills align with the job description?\n            * **Score:** (1-5, where 1 is \"Irrelevant skills\" and 5 is \"Excellent match + AI/LLM exposure\")\n            * **Feedback:** [Provide a brief justification for the score, highlighting key strengths or gaps in skills.]\n\n        2.  **Experience Level (1-5):**\n            * **Description:** Assess the candidate's years of experience and the complexity of their past projects.\n            * **Score:** (1-5, where 1 is \"<1 yr / trivial projects\" and 5 is \"5+ yrs / high-impact projects\")\n            * **Feedback:** [Provide a brief justification for the score, mentioning project scope or years of experience.]\n\n        3.  **Relevant Achievements (1-5):**\n            * **Description:** Evaluate the impact and scale of the candidate's past work. Look for measurable outcomes.\n            * **Score:** (1-5, where 1 is \"No clear achievements\" and 5 is \"Major measurable impact\")\n            * **Feedback:** [Provide a brief justification for the score, citing specific achievements or noting their absence.]\n\n        4.  **Cultural Fit (1-5):**\n            * **Description:** Based on the CV's tone and content, assess the candidate's communication skills and learning attitude.\n            * **Score:** (1-5, where 1 is \"Not demonstrated\" and 5 is \"Excellent and well-demonstrated\")\n            * **Feedback:** [Provide a brief justification for the score, commenting on clarity, detail, or demonstrated a growth mindset.]\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n\ntest evaluate_all {\n  functions [EvaluateAll]\n  args {\n        cv {\n            name: \"Ricky Alturino\",\n            address: \"Palembang, Indonesia\",\n            projects: [\n                {\n                name: \"Hedonify\",\n                description: \"Scalable ecommerce microservices-based backend system, implemented a queue and batch processing to handle competing orders efficiently.\",\n                technologies: [\n                    \"Go\",\n                    \"Docker\",\n                    \"Microservice\",\n                    \"PostgreSQL\",\n                    \"Redis\",\n                    \"OpenTelemetry\"\n                ],\n                tools: [],\n                duration_in_year: 0.92\n                },\n                {\n                name: \"Open Music API\",\n                description: \"Music backend server for dicoding course.\",\n                technologies: [\n                    \"JavaScript (Hapi)\",\n                    \"Java (Spring Boot)\",\n                    \"PostgreSQL\",\n                    \"RabbitMQ\"\n                ],\n                tools: [],\n                duration_in_year: 0.5\n                },\n                {\n                name: \"Learn Kubernetes\",\n                description: \"Learn kubernetes deployment and database replication of MongoDB, PostgreSQL, and Redis by using Docker Compose and Kubernetes StatefulSet.\",\n                technologies: [\n                    \"MongoDB\",\n                    \"PostgreSQL\",\n                    \"Redis\",\n                    \"Docker\",\n                    \"Kubernetes\"\n                ],\n                tools: [],\n                duration_in_year: 0.08\n                }\n            ],\n            educations: [\n                {\n                school: \"Sriwijaya University\",\n                gpa: 3.6,\n                max_gpa: 4\n                }\n            ],\n            experience: [\n                {\n                company: \"Brick\",\n                position: \"L1 Engineer\",\n                location: \"(Remote) Jakarta, Indonesia\",\n                start_date: \"May 2024\",\n                end_date: \"May 2025\",\n                duration_in_year: 1.08,\n                description: \"\",\n                responsibilities: [\n                    \"Provide cross-divisional support both in data updates and data retrieval.\",\n                    \"Developed, maintained applications/services.\"\n                ]\n                },\n                {\n                company: \"Campaign\",\n                position: \"Android Developer Intern\",\n                location: \"(Remote) Jakarta, Indonesia\",\n                start_date: \"January 2023\",\n                end_date: \"July 2023\",\n                duration_in_year: 0.58,\n                description: \"\",\n                responsibilities: [\n                    \"Collaborated with teams to ensure features are meeting expectations.\",\n                    \"Developed, maintained, and tested new features.\"\n                ]\n                },\n                {\n                company: \"Indosat Ooredoo Hutchison\",\n                position: \"Android Developer Intern\",\n                location: \"(Remote) Jakarta, Indonesia\",\n                start_date: \"May 2022\",\n                end_date: \"June 2022\",\n                duration_in_year: 0.17,\n                description: \"\",\n                responsibilities: [\n                    \"Lead Mobile Development Team to develop Hy.Ponics application.\",\n                    \"Researched, developed, and tested features of Hy.Ponics application.\"\n                ]\n                }\n            ],\n            skills: [\n                \"Go\",\n                \"Java\",\n                \"Kotlin\",\n                \"TypeScript\",\n                \"Python\",\n                \"OOP\",\n                \"Design Pattern\",\n                \"TDD\",\n                \"Gin\",\n                \"Fiber\",\n                \"Echo\",\n                \"Spring Boot\",\n                \"Express\",\n                \"Hapi\",\n                \"NestJS\",\n                \"React\",\n                \"Github Actions\",\n                \"Circle CI\",\n                \"PostgreSQL\",\n                \"MySQL\",\n                \"MongoDB\",\n                \"Redis\",\n                \"Memcached\",\n                \"Firebase\",\n                \"RabbitMQ\",\n                \"Kafka\",\n                \"NATS\",\n                \"Firebase Cloud Messaging\",\n                \"Git\",\n                \"Linux\",\n                \"Docker\",\n                \"Kubernetes\",\n                \"k6\",\n                \"Testcontainers\",\n                \"Prometheus\",\n                \"Grafana\",\n                \"Nginx\",\n                \"AWS\",\n                \"GCP\"\n            ]\n} \n    job_description {\n        description: \"You'll be building new product features alongside a frontend engineer and product manager using our Agile methodology, as well as addressing issues to ensure our apps are robust and our codebase is clean. As a Product Engineer, you'll write clean, efficient code to enhance our product's codebase in meaningful ways. In addition to classic backend work, this role also touches on building AI-powered systems, where you’ll design and orchestrate how large language models (LLMs) integrate into Rakamin’s product ecosystem.\",\n        qualifications: [\n            \"Strong track record of working on backend technologies of web apps\",\n            \"Exposure to AI/LLM development or a strong desire to learn\",\n            \"Experience with backend languages and frameworks (Node.js, Django, Rails)\",\n            \"Experience with Database management (MySQL, PostgreSQL, MongoDB)\",\n            \"Experience with RESTful APIs\",\n            \"Experience with Security compliance\",\n            \"Experience with Cloud technologies (AWS, Google Cloud, Azure)\",\n            \"Experience with Server-side languages (Java, Python, Ruby, or JavaScript)\",\n            \"Understanding of frontend technologies\",\n            \"Experience with User authentication and authorization between multiple systems, servers, and environments\",\n            \"Knowledge of Scalable application design principles\",\n            \"Experience creating database schemas that represent and support business processes\",\n            \"Experience implementing automated testing platforms and unit tests\",\n            \"Familiarity with LLM APIs, embeddings, vector databases and prompt design best practices\",\n            \"Ability to demonstrate practical skills and how work is done, rather than solely relying on academic credentials (e.g., Computer Science degree or prestigious university)\"\n        ],\n        tools: [\n            \"Node.js\",\n            \"Ruby on Rails\",\n            \"LLM\",\n            \"Docker\",\n            \"Kubernetes\",\n            \"Django\",\n            \"MySQL\",\n            \"PostgreSQL\",\n            \"MongoDB\",\n            \"AWS\",\n            \"Google Cloud\",\n            \"Azure\",\n            \"Java\",\n            \"Python\",\n            \"Ruby\",\n            \"JavaScript\",\n            \"RSpec\",\n            \"Vector databases\"\n        ],\n        real_work_examples: [\n            \"Collaborating with frontend engineers and 3rd parties to build robust backend solutions that support highly configurable platforms and cross-platform integration.\",\n            \"Developing and maintaining server-side logic for central database, ensuring high performance throughput and response time.\",\n            \"Designing and fine-tuning AI prompts that align with product requirements and user contexts.\",\n            \"Building LLM chaining flows, where the output from one model is reliably passed to and enriched by another.\",\n            \"Implementing Retrieval-Augmented Generation (RAG) by embedding and retrieving context from vector databases, then injecting it into AI prompts to improve accuracy and relevance.\",\n            \"Handling long-running AI processes gracefully — including job orchestration, async background workers, and retry mechanisms.\",\n            \"Designing safeguards for uncontrolled scenarios: managing failure cases from 3rd party APIs and mitigating the randomness/nondeterminism of LLM outputs.\",\n            \"Leveraging AI tools and workflows to increase team productivity (e.g., AI-assisted code generation, automated QA, internal bots).\",\n            \"Writing reusable, testable, and efficient code to improve the functionality of our existing systems.\",\n            \"Strengthening our test coverage with RSpec to build robust and reliable web apps.\",\n            \"Conducting full product lifecycles, from idea generation to design, implementation, testing, deployment, and maintenance.\",\n            \"Providing input on technical feasibility, timelines, and potential product trade-offs, working with business divisions.\",\n            \"Actively engaging with users and stakeholders to understand their needs and translate them into backend and AI-driven improvements.\"\n        ]\n    } \n    project_evaluation {\n        overall 4.7\n        correctness 2\n        code_quality 4\n        resilience 2,\n        documentation 1\n        creativity_and_bonus 2.5\n        feedback \"This project provides a basic FastAPI application for uploading documents and triggering a conversion process. While the code structure is generally clean and utilizes good practices in some areas, there are critical issues in correctness, resilience, and a complete lack of external documentation.\\n\\n### Detailed Feedback:\\n\\n**1. Correctness (2.0/5)**\\n*   **`/upload` Endpoint:** This endpoint correctly handles file uploads, validates extensions, generates a unique ID, stores the file on disk, encodes its content to base64, and saves metadata to the database. Error handling for missing filenames and disallowed extensions is present.\\n*   **`/evaluate` Endpoint - Critical Logic Flaw:** The most significant correctness issue lies within the `/evaluate` endpoint's database query logic. The query for both the `cv` and `project` documents uses `Document.id == req_body.id`. However, the `/upload` endpoint assigns a *new, unique* `uuid.uuid4()` to each `Document` when it's uploaded. This means it's highly unlikely that a separate `cv` file and `project` file would ever share the same `Document.id`. Consequently, the query for the `project` document will almost always fail (`project` will be `None`), unless the `cv_file` and `project_file` refer to the same physical document, or there's an unstated linking mechanism. This design flaw makes it impossible to correctly retrieve and process two distinct documents (CV and project) in the `evaluate` endpoint as currently implemented.\\n*   **`/evaluate` Endpoint - Incomplete Processing Feedback:** The `doc_converter.convert(path)` method is called, but its return value (`conv_res`) is ignored. More critically, the endpoint *always* returns `JSONResponse({\\\"status\\\": \\\"ok\\\", \\\"message\\\": \\\"ok\\\"})`, regardless of whether `doc_converter.convert` succeeded or failed. If the conversion fails or throws an exception, the client receives a misleading 'ok' status or a 500 error, without any specific error reporting.\\n*   **LLM/RAG/Prompt Design:** These aspects were not applicable as the provided code does not demonstrate any LLM interaction, RAG, or prompt design.\\n\\n**2. Code Quality (4.0/5)**\\n*   **Cleanliness & Readability:** The code is generally clean, well-formatted, and uses descriptive variable and function names. Imports are grouped logically.\\n*   **Modularity:** The separation of database models (`model.db`, `model.document`), request bodies (`model.requests.body`), and the use of external libraries (`docling`, `FastAPI`, `SQLModel`) demonstrate good modular design.\\n*   **Best Practices:** Uses `async/await` for I/O, `pathlib` for robust path handling, context managers for database sessions, and `logging`. Environment variables are loaded via `dotenv`. SQLModel usage is appropriate.\\n*   **Minor Issues:** `MAX_REQUEST_SIZE` is declared but unused. The file content is read into memory, base64 encoded for DB storage, and then the original content is written to disk. For very large files, this could be slightly inefficient by holding the full file content in memory twice.\\n\\n**3. Resilience (2.0/5)**\\n*   **Basic Error Handling:** Input validation for filenames and extensions is present in `/upload`, and missing CV files are handled in `/evaluate`. FastAPI's `HTTPException` is used correctly for these cases.\\n*   **Lack of Robust Error Handling for Processing:** The `evaluate` endpoint lacks robust error handling for the `DocumentConverter`. Any failure during conversion will either lead to a silent success message or a 500 Internal Server Error, rather than a graceful and informative response to the client.\\n*   **No Request Size Enforcement:** The `MAX_REQUEST_SIZE` constant is defined but not enforced in the `/upload` endpoint. This makes the service vulnerable to Denial-of-Service (DoS) attacks via excessively large file uploads.\\n*   **No Retries/Circuit Breakers:** There are no explicit retry mechanisms for external dependencies (like database connections or the `DocumentConverter`) or any form of circuit breaking for transient failures.\\n*   **Limited Monitoring:** Basic logging is implemented, but there's no evidence of more advanced monitoring, metrics, or tracing.\\n\\n**4. Documentation (1.0/5)**\\n*   **Internal Documentation:** The provided source file contains almost no comments or docstrings explaining the purpose of functions, classes, or complex logic. This makes the code harder to understand and maintain without prior knowledge of the system.\\n*   **External Documentation:** There is no README file, API documentation (e.g., OpenAPI specification beyond what FastAPI generates automatically), architectural decisions, or trade-offs explained. For an 'expert technical reviewer', this is a significant oversight.\\n\\n**5. Creativity/Bonus (2.5/5)**\\n*   **Library Choices:** The use of modern libraries like `FastAPI`, `SQLModel`, and `pathlib` is a positive aspect.\\n*   **Database Migrations:** The `migrations()` call suggests a proper database migration setup, which is good practice.\\n*   **Base64 Encoding:** Storing base64 encoded content directly in the database is a design choice. While it might be convenient for smaller files, it can be inefficient for larger documents in terms of database size, query performance, and memory usage. Storing a reference and retrieving from disk on demand is often preferred for larger binaries.\\n*   **Missed Opportunities:** The unused `MAX_REQUEST_SIZE` is a missed opportunity for a crucial security/resilience feature. There are no advanced security considerations (e.g., authentication, authorization beyond simple input validation), performance optimizations (e.g., async processing, caching), or deployment considerations evident in the provided code.\\n\\n### Overall Summary:\\n\\nThe project provides a functional skeleton for document processing. The code quality is reasonable for its scope, but the fundamental logic for retrieving and processing multiple documents in the `evaluate` endpoint is flawed. The lack of robust error handling for the core business logic (document conversion), combined with a total absence of documentation, significantly impacts its production readiness and maintainability. Addressing the correctness issues in `/evaluate` and enhancing resilience and documentation should be top priorities.\"\n    } \n  }\n}",
}

def get_baml_files():
    return _file_map